%%% % DO NOT EDIT: this file was generated by 'just codegen'
%%% % @generated <<SignedSource::*O*zOeWoEQle#+L!plEphiEmie@IsG>>
%%% % @format
%%%-----------------------------------------------------------------------------
%%% Copyright (c) Meta Platforms, Inc. and affiliates.
%%% Copyright (c) WhatsApp LLC
%%%
%%% This source code is licensed under the MIT license found in the
%%% LICENSE.md file in the root directory of this source tree.
%%%
%%% @author Andrew Bennett <potatosaladx@meta.com>
%%% @copyright (c) Meta Platforms, Inc. and affiliates.
%%% Created :  04 Mar 2025 by Andrew Bennett <potatosaladx@meta.com>
%%%-----------------------------------------------------------------------------
-module(markdown_state).
-moduledoc """
States of the state machine.
""".
-compile(warn_missing_spec_all).
-oncall("whatsapp_clr").

-include_lib("markdown/include/markdown_parser.hrl").
-include_lib("markdown/include/markdown_state.hrl").

%% API
-export([
    error/1,
    next/1,
    nok/0,
    ok/0,
    retry/1,
    to_result/1
]).
%% Call API
-export([
    call/2,
    attention_start/1,
    attention_inside/1,
    attribute_list_flow_start/1,
    attribute_list_flow_before/1,
    attribute_list_flow_after/1,
    attribute_list_start/1,
    attribute_list_before/1,
    attribute_list_inside/1,
    attribute_list_eol_after/1,
    autolink_start/1,
    autolink_open/1,
    autolink_scheme_or_email_atext/1,
    autolink_scheme_inside_or_email_atext/1,
    autolink_url_inside/1,
    autolink_email_at_sign_or_dot/1,
    autolink_email_atext/1,
    autolink_email_value/1,
    autolink_email_label/1,
    blank_line_start/1,
    blank_line_after/1,
    block_quote_start/1,
    block_quote_cont_start/1,
    block_quote_cont_before/1,
    block_quote_cont_after/1,
    bom_start/1,
    bom_inside/1,
    character_escape_start/1,
    character_escape_inside/1,
    character_reference_start/1,
    character_reference_open/1,
    character_reference_numeric/1,
    character_reference_value/1,
    code_indented_start/1,
    code_indented_at_break/1,
    code_indented_after/1,
    code_indented_further_start/1,
    code_indented_inside/1,
    code_indented_further_begin/1,
    code_indented_further_after/1,
    content_chunk_start/1,
    content_chunk_inside/1,
    content_definition_before/1,
    content_definition_after/1,
    data_start/1,
    data_inside/1,
    data_at_break/1,
    definition_start/1,
    definition_before/1,
    definition_label_after/1,
    definition_label_nok/1,
    definition_marker_after/1,
    definition_destination_before/1,
    definition_destination_after/1,
    definition_destination_missing/1,
    definition_title_before/1,
    definition_after/1,
    definition_after_whitespace/1,
    definition_title_before_marker/1,
    definition_title_after/1,
    definition_title_after_optional_whitespace/1,
    destination_start/1,
    destination_enclosed_before/1,
    destination_enclosed/1,
    destination_enclosed_escape/1,
    destination_raw/1,
    destination_raw_escape/1,
    document_start/1,
    document_before_frontmatter/1,
    document_container_existing_before/1,
    document_container_existing_after/1,
    document_container_new_before/1,
    document_container_new_before_not_block_quote/1,
    document_container_new_before_not_list/1,
    document_container_new_before_not_gfm_footnote_definition/1,
    document_container_new_after/1,
    document_containers_after/1,
    document_flow_end/1,
    document_flow_inside/1,
    flow_start/1,
    flow_before_attribute_list/1,
    flow_before_gfm_table/1,
    flow_before_code_indented/1,
    flow_before_raw/1,
    flow_before_html/1,
    flow_before_mdx_expression/1,
    flow_before_mdx_jsx/1,
    flow_before_heading_atx/1,
    flow_before_heading_setext/1,
    flow_before_thematic_break/1,
    flow_after/1,
    flow_blank_line_before/1,
    flow_blank_line_after/1,
    flow_before_content/1,
    frontmatter_start/1,
    frontmatter_open_sequence/1,
    frontmatter_open_after/1,
    frontmatter_after/1,
    frontmatter_content_start/1,
    frontmatter_content_inside/1,
    frontmatter_content_end/1,
    frontmatter_close_start/1,
    frontmatter_close_sequence/1,
    frontmatter_close_after/1,
    gfm_autolink_literal_protocol_start/1,
    gfm_autolink_literal_protocol_after/1,
    gfm_autolink_literal_protocol_prefix_inside/1,
    gfm_autolink_literal_protocol_slashes_inside/1,
    gfm_autolink_literal_www_after/1,
    gfm_autolink_literal_www_start/1,
    gfm_autolink_literal_www_prefix_inside/1,
    gfm_autolink_literal_www_prefix_after/1,
    gfm_autolink_literal_domain_inside/1,
    gfm_autolink_literal_domain_at_punctuation/1,
    gfm_autolink_literal_domain_after/1,
    gfm_autolink_literal_path_inside/1,
    gfm_autolink_literal_path_at_punctuation/1,
    gfm_autolink_literal_path_after/1,
    gfm_autolink_literal_trail/1,
    gfm_autolink_literal_trail_char_ref_start/1,
    gfm_autolink_literal_trail_char_ref_inside/1,
    gfm_autolink_literal_trail_bracket_after/1,
    gfm_footnote_definition_start/1,
    gfm_footnote_definition_label_before/1,
    gfm_footnote_definition_label_at_marker/1,
    gfm_footnote_definition_label_inside/1,
    gfm_footnote_definition_label_escape/1,
    gfm_footnote_definition_label_after/1,
    gfm_footnote_definition_whitespace_after/1,
    gfm_footnote_definition_cont_start/1,
    gfm_footnote_definition_cont_blank/1,
    gfm_footnote_definition_cont_filled/1,
    gfm_label_start_footnote_start/1,
    gfm_label_start_footnote_open/1,
    gfm_table_start/1,
    gfm_table_head_row_before/1,
    gfm_table_head_row_start/1,
    gfm_table_head_row_break/1,
    gfm_table_head_row_data/1,
    gfm_table_head_row_escape/1,
    gfm_table_head_delimiter_start/1,
    gfm_table_head_delimiter_before/1,
    gfm_table_head_delimiter_cell_before/1,
    gfm_table_head_delimiter_value_before/1,
    gfm_table_head_delimiter_left_alignment_after/1,
    gfm_table_head_delimiter_filler/1,
    gfm_table_head_delimiter_right_alignment_after/1,
    gfm_table_head_delimiter_cell_after/1,
    gfm_table_head_delimiter_nok/1,
    gfm_table_body_row_start/1,
    gfm_table_body_row_break/1,
    gfm_table_body_row_data/1,
    gfm_table_body_row_escape/1,
    gfm_task_list_item_check_start/1,
    gfm_task_list_item_check_inside/1,
    gfm_task_list_item_check_close/1,
    gfm_task_list_item_check_after/1,
    gfm_task_list_item_check_after_space_or_tab/1,
    hard_break_escape_start/1,
    hard_break_escape_after/1,
    heading_atx_start/1,
    heading_atx_before/1,
    heading_atx_sequence_open/1,
    heading_atx_at_break/1,
    heading_atx_sequence_further/1,
    heading_atx_data/1,
    heading_setext_start/1,
    heading_setext_before/1,
    heading_setext_inside/1,
    heading_setext_after/1,
    html_flow_start/1,
    html_flow_before/1,
    html_flow_open/1,
    html_flow_declaration_open/1,
    html_flow_comment_open_inside/1,
    html_flow_cdata_open_inside/1,
    html_flow_tag_close_start/1,
    html_flow_tag_name/1,
    html_flow_basic_self_closing/1,
    html_flow_complete_closing_tag_after/1,
    html_flow_complete_end/1,
    html_flow_complete_attribute_name_before/1,
    html_flow_complete_attribute_name/1,
    html_flow_complete_attribute_name_after/1,
    html_flow_complete_attribute_value_before/1,
    html_flow_complete_attribute_value_quoted/1,
    html_flow_complete_attribute_value_quoted_after/1,
    html_flow_complete_attribute_value_unquoted/1,
    html_flow_complete_after/1,
    html_flow_blank_line_before/1,
    html_flow_continuation/1,
    html_flow_continuation_declaration_inside/1,
    html_flow_continuation_after/1,
    html_flow_continuation_start/1,
    html_flow_continuation_before/1,
    html_flow_continuation_comment_inside/1,
    html_flow_continuation_raw_tag_open/1,
    html_flow_continuation_raw_end_tag/1,
    html_flow_continuation_close/1,
    html_flow_continuation_cdata_inside/1,
    html_flow_continuation_start_non_lazy/1,
    html_text_start/1,
    html_text_open/1,
    html_text_declaration_open/1,
    html_text_tag_close_start/1,
    html_text_tag_close/1,
    html_text_tag_close_between/1,
    html_text_tag_open/1,
    html_text_tag_open_between/1,
    html_text_tag_open_attribute_name/1,
    html_text_tag_open_attribute_name_after/1,
    html_text_tag_open_attribute_value_before/1,
    html_text_tag_open_attribute_value_quoted/1,
    html_text_tag_open_attribute_value_quoted_after/1,
    html_text_tag_open_attribute_value_unquoted/1,
    html_text_cdata/1,
    html_text_cdata_open_inside/1,
    html_text_cdata_close/1,
    html_text_cdata_end/1,
    html_text_comment_open_inside/1,
    html_text_comment/1,
    html_text_comment_close/1,
    html_text_comment_end/1,
    html_text_declaration/1,
    html_text_end/1,
    html_text_instruction/1,
    html_text_instruction_close/1,
    html_text_line_ending_before/1,
    html_text_line_ending_after/1,
    html_text_line_ending_after_prefix/1,
    label_start/1,
    label_at_break/1,
    label_eol_after/1,
    label_escape/1,
    label_inside/1,
    label_nok/1,
    label_end_start/1,
    label_end_after/1,
    label_end_resource_start/1,
    label_end_resource_before/1,
    label_end_resource_open/1,
    label_end_resource_destination_after/1,
    label_end_resource_destination_missing/1,
    label_end_resource_between/1,
    label_end_resource_title_after/1,
    label_end_resource_end/1,
    label_end_ok/1,
    label_end_nok/1,
    label_end_reference_full/1,
    label_end_reference_full_after/1,
    label_end_reference_full_missing/1,
    label_end_reference_not_full/1,
    label_end_reference_collapsed/1,
    label_end_reference_collapsed_open/1,
    label_start_image_start/1,
    label_start_image_open/1,
    label_start_image_after/1,
    label_start_link_start/1,
    list_item_start/1,
    list_item_before/1,
    list_item_before_ordered/1,
    list_item_before_unordered/1,
    list_item_value/1,
    list_item_marker/1,
    list_item_marker_after/1,
    list_item_after/1,
    list_item_marker_after_filled/1,
    list_item_whitespace/1,
    list_item_whitespace_after/1,
    list_item_prefix_other/1,
    list_item_cont_start/1,
    list_item_cont_blank/1,
    list_item_cont_filled/1,
    mdx_esm_start/1,
    mdx_esm_word/1,
    mdx_esm_inside/1,
    mdx_esm_line_start/1,
    mdx_esm_blank_line_before/1,
    mdx_esm_continuation_start/1,
    mdx_esm_at_end/1,
    mdx_expression_start/1,
    mdx_expression_prefix/1,
    mdx_expression_before/1,
    mdx_expression_inside/1,
    mdx_expression_eol_after/1,
    mdx_expression_flow_start/1,
    mdx_expression_flow_before/1,
    mdx_expression_flow_after/1,
    mdx_expression_flow_end/1,
    mdx_expression_text_start/1,
    mdx_expression_text_after/1,
    mdx_jsx_flow_start/1,
    mdx_jsx_flow_before/1,
    mdx_jsx_flow_after/1,
    mdx_jsx_flow_end/1,
    mdx_jsx_flow_nok/1,
    mdx_jsx_text_start/1,
    mdx_jsx_text_after/1,
    mdx_jsx_text_nok/1,
    mdx_jsx_start/1,
    mdx_jsx_start_after/1,
    mdx_jsx_name_before/1,
    mdx_jsx_closing_tag_name_before/1,
    mdx_jsx_tag_end/1,
    mdx_jsx_primary_name/1,
    mdx_jsx_primary_name_after/1,
    mdx_jsx_member_name_before/1,
    mdx_jsx_member_name/1,
    mdx_jsx_member_name_after/1,
    mdx_jsx_local_name_before/1,
    mdx_jsx_local_name/1,
    mdx_jsx_local_name_after/1,
    mdx_jsx_attribute_before/1,
    mdx_jsx_self_closing/1,
    mdx_jsx_attribute_expression_after/1,
    mdx_jsx_attribute_primary_name/1,
    mdx_jsx_attribute_primary_name_after/1,
    mdx_jsx_attribute_local_name_before/1,
    mdx_jsx_attribute_local_name/1,
    mdx_jsx_attribute_local_name_after/1,
    mdx_jsx_attribute_value_before/1,
    mdx_jsx_attribute_value_quoted_start/1,
    mdx_jsx_attribute_value_quoted/1,
    mdx_jsx_attribute_value_expression_after/1,
    mdx_jsx_es_whitespace_start/1,
    mdx_jsx_es_whitespace_inside/1,
    mdx_jsx_es_whitespace_eol_after/1,
    non_lazy_continuation_start/1,
    non_lazy_continuation_after/1,
    paragraph_start/1,
    paragraph_line_start/1,
    paragraph_inside/1,
    raw_flow_start/1,
    raw_flow_before_sequence_open/1,
    raw_flow_sequence_open/1,
    raw_flow_info_before/1,
    raw_flow_info/1,
    raw_flow_meta_before/1,
    raw_flow_meta/1,
    raw_flow_at_non_lazy_break/1,
    raw_flow_close_start/1,
    raw_flow_before_sequence_close/1,
    raw_flow_sequence_close/1,
    raw_flow_after_sequence_close/1,
    raw_flow_content_before/1,
    raw_flow_content_start/1,
    raw_flow_before_content_chunk/1,
    raw_flow_content_chunk/1,
    raw_flow_after/1,
    raw_text_start/1,
    raw_text_sequence_open/1,
    raw_text_between/1,
    raw_text_data/1,
    raw_text_sequence_close/1,
    space_or_tab_start/1,
    space_or_tab_inside/1,
    space_or_tab_after/1,
    space_or_tab_eol_start/1,
    space_or_tab_eol_after_first/1,
    space_or_tab_eol_after_eol/1,
    space_or_tab_eol_at_eol/1,
    space_or_tab_eol_after_more/1,
    string_start/1,
    string_before/1,
    string_before_data/1,
    text_start/1,
    text_before/1,
    text_before_html/1,
    text_before_mdx_jsx/1,
    text_before_hard_break_escape/1,
    text_before_label_start_link/1,
    text_before_data/1,
    thematic_break_start/1,
    thematic_break_before/1,
    thematic_break_sequence/1,
    thematic_break_at_break/1,
    title_start/1,
    title_begin/1,
    title_after_eol/1,
    title_at_break/1,
    title_escape/1,
    title_inside/1,
    title_nok/1
]).

%% Types
-doc """
Syntax error.

Only used by MDX.
""".
-type error() :: {error, dynamic()}.

-doc "Names of states to move to.".
-type name() ::
    attention_start
    | attention_inside
    | attribute_list_flow_start
    | attribute_list_flow_before
    | attribute_list_flow_after
    | attribute_list_start
    | attribute_list_before
    | attribute_list_inside
    | attribute_list_eol_after
    | autolink_start
    | autolink_open
    | autolink_scheme_or_email_atext
    | autolink_scheme_inside_or_email_atext
    | autolink_url_inside
    | autolink_email_at_sign_or_dot
    | autolink_email_atext
    | autolink_email_value
    | autolink_email_label
    | blank_line_start
    | blank_line_after
    | block_quote_start
    | block_quote_cont_start
    | block_quote_cont_before
    | block_quote_cont_after
    | bom_start
    | bom_inside
    | character_escape_start
    | character_escape_inside
    | character_reference_start
    | character_reference_open
    | character_reference_numeric
    | character_reference_value
    | code_indented_start
    | code_indented_at_break
    | code_indented_after
    | code_indented_further_start
    | code_indented_inside
    | code_indented_further_begin
    | code_indented_further_after
    | content_chunk_start
    | content_chunk_inside
    | content_definition_before
    | content_definition_after
    | data_start
    | data_inside
    | data_at_break
    | definition_start
    | definition_before
    | definition_label_after
    | definition_label_nok
    | definition_marker_after
    | definition_destination_before
    | definition_destination_after
    | definition_destination_missing
    | definition_title_before
    | definition_after
    | definition_after_whitespace
    | definition_title_before_marker
    | definition_title_after
    | definition_title_after_optional_whitespace
    | destination_start
    | destination_enclosed_before
    | destination_enclosed
    | destination_enclosed_escape
    | destination_raw
    | destination_raw_escape
    | document_start
    | document_before_frontmatter
    | document_container_existing_before
    | document_container_existing_after
    | document_container_new_before
    | document_container_new_before_not_block_quote
    | document_container_new_before_not_list
    | document_container_new_before_not_gfm_footnote_definition
    | document_container_new_after
    | document_containers_after
    | document_flow_end
    | document_flow_inside
    | flow_start
    | flow_before_attribute_list
    | flow_before_gfm_table
    | flow_before_code_indented
    | flow_before_raw
    | flow_before_html
    | flow_before_mdx_expression
    | flow_before_mdx_jsx
    | flow_before_heading_atx
    | flow_before_heading_setext
    | flow_before_thematic_break
    | flow_after
    | flow_blank_line_before
    | flow_blank_line_after
    | flow_before_content
    | frontmatter_start
    | frontmatter_open_sequence
    | frontmatter_open_after
    | frontmatter_after
    | frontmatter_content_start
    | frontmatter_content_inside
    | frontmatter_content_end
    | frontmatter_close_start
    | frontmatter_close_sequence
    | frontmatter_close_after
    | gfm_autolink_literal_protocol_start
    | gfm_autolink_literal_protocol_after
    | gfm_autolink_literal_protocol_prefix_inside
    | gfm_autolink_literal_protocol_slashes_inside
    | gfm_autolink_literal_www_after
    | gfm_autolink_literal_www_start
    | gfm_autolink_literal_www_prefix_inside
    | gfm_autolink_literal_www_prefix_after
    | gfm_autolink_literal_domain_inside
    | gfm_autolink_literal_domain_at_punctuation
    | gfm_autolink_literal_domain_after
    | gfm_autolink_literal_path_inside
    | gfm_autolink_literal_path_at_punctuation
    | gfm_autolink_literal_path_after
    | gfm_autolink_literal_trail
    | gfm_autolink_literal_trail_char_ref_start
    | gfm_autolink_literal_trail_char_ref_inside
    | gfm_autolink_literal_trail_bracket_after
    | gfm_footnote_definition_start
    | gfm_footnote_definition_label_before
    | gfm_footnote_definition_label_at_marker
    | gfm_footnote_definition_label_inside
    | gfm_footnote_definition_label_escape
    | gfm_footnote_definition_label_after
    | gfm_footnote_definition_whitespace_after
    | gfm_footnote_definition_cont_start
    | gfm_footnote_definition_cont_blank
    | gfm_footnote_definition_cont_filled
    | gfm_label_start_footnote_start
    | gfm_label_start_footnote_open
    | gfm_table_start
    | gfm_table_head_row_before
    | gfm_table_head_row_start
    | gfm_table_head_row_break
    | gfm_table_head_row_data
    | gfm_table_head_row_escape
    | gfm_table_head_delimiter_start
    | gfm_table_head_delimiter_before
    | gfm_table_head_delimiter_cell_before
    | gfm_table_head_delimiter_value_before
    | gfm_table_head_delimiter_left_alignment_after
    | gfm_table_head_delimiter_filler
    | gfm_table_head_delimiter_right_alignment_after
    | gfm_table_head_delimiter_cell_after
    | gfm_table_head_delimiter_nok
    | gfm_table_body_row_start
    | gfm_table_body_row_break
    | gfm_table_body_row_data
    | gfm_table_body_row_escape
    | gfm_task_list_item_check_start
    | gfm_task_list_item_check_inside
    | gfm_task_list_item_check_close
    | gfm_task_list_item_check_after
    | gfm_task_list_item_check_after_space_or_tab
    | hard_break_escape_start
    | hard_break_escape_after
    | heading_atx_start
    | heading_atx_before
    | heading_atx_sequence_open
    | heading_atx_at_break
    | heading_atx_sequence_further
    | heading_atx_data
    | heading_setext_start
    | heading_setext_before
    | heading_setext_inside
    | heading_setext_after
    | html_flow_start
    | html_flow_before
    | html_flow_open
    | html_flow_declaration_open
    | html_flow_comment_open_inside
    | html_flow_cdata_open_inside
    | html_flow_tag_close_start
    | html_flow_tag_name
    | html_flow_basic_self_closing
    | html_flow_complete_closing_tag_after
    | html_flow_complete_end
    | html_flow_complete_attribute_name_before
    | html_flow_complete_attribute_name
    | html_flow_complete_attribute_name_after
    | html_flow_complete_attribute_value_before
    | html_flow_complete_attribute_value_quoted
    | html_flow_complete_attribute_value_quoted_after
    | html_flow_complete_attribute_value_unquoted
    | html_flow_complete_after
    | html_flow_blank_line_before
    | html_flow_continuation
    | html_flow_continuation_declaration_inside
    | html_flow_continuation_after
    | html_flow_continuation_start
    | html_flow_continuation_before
    | html_flow_continuation_comment_inside
    | html_flow_continuation_raw_tag_open
    | html_flow_continuation_raw_end_tag
    | html_flow_continuation_close
    | html_flow_continuation_cdata_inside
    | html_flow_continuation_start_non_lazy
    | html_text_start
    | html_text_open
    | html_text_declaration_open
    | html_text_tag_close_start
    | html_text_tag_close
    | html_text_tag_close_between
    | html_text_tag_open
    | html_text_tag_open_between
    | html_text_tag_open_attribute_name
    | html_text_tag_open_attribute_name_after
    | html_text_tag_open_attribute_value_before
    | html_text_tag_open_attribute_value_quoted
    | html_text_tag_open_attribute_value_quoted_after
    | html_text_tag_open_attribute_value_unquoted
    | html_text_cdata
    | html_text_cdata_open_inside
    | html_text_cdata_close
    | html_text_cdata_end
    | html_text_comment_open_inside
    | html_text_comment
    | html_text_comment_close
    | html_text_comment_end
    | html_text_declaration
    | html_text_end
    | html_text_instruction
    | html_text_instruction_close
    | html_text_line_ending_before
    | html_text_line_ending_after
    | html_text_line_ending_after_prefix
    | label_start
    | label_at_break
    | label_eol_after
    | label_escape
    | label_inside
    | label_nok
    | label_end_start
    | label_end_after
    | label_end_resource_start
    | label_end_resource_before
    | label_end_resource_open
    | label_end_resource_destination_after
    | label_end_resource_destination_missing
    | label_end_resource_between
    | label_end_resource_title_after
    | label_end_resource_end
    | label_end_ok
    | label_end_nok
    | label_end_reference_full
    | label_end_reference_full_after
    | label_end_reference_full_missing
    | label_end_reference_not_full
    | label_end_reference_collapsed
    | label_end_reference_collapsed_open
    | label_start_image_start
    | label_start_image_open
    | label_start_image_after
    | label_start_link_start
    | list_item_start
    | list_item_before
    | list_item_before_ordered
    | list_item_before_unordered
    | list_item_value
    | list_item_marker
    | list_item_marker_after
    | list_item_after
    | list_item_marker_after_filled
    | list_item_whitespace
    | list_item_whitespace_after
    | list_item_prefix_other
    | list_item_cont_start
    | list_item_cont_blank
    | list_item_cont_filled
    | mdx_esm_start
    | mdx_esm_word
    | mdx_esm_inside
    | mdx_esm_line_start
    | mdx_esm_blank_line_before
    | mdx_esm_continuation_start
    | mdx_esm_at_end
    | mdx_expression_start
    | mdx_expression_prefix
    | mdx_expression_before
    | mdx_expression_inside
    | mdx_expression_eol_after
    | mdx_expression_flow_start
    | mdx_expression_flow_before
    | mdx_expression_flow_after
    | mdx_expression_flow_end
    | mdx_expression_text_start
    | mdx_expression_text_after
    | mdx_jsx_flow_start
    | mdx_jsx_flow_before
    | mdx_jsx_flow_after
    | mdx_jsx_flow_end
    | mdx_jsx_flow_nok
    | mdx_jsx_text_start
    | mdx_jsx_text_after
    | mdx_jsx_text_nok
    | mdx_jsx_start
    | mdx_jsx_start_after
    | mdx_jsx_name_before
    | mdx_jsx_closing_tag_name_before
    | mdx_jsx_tag_end
    | mdx_jsx_primary_name
    | mdx_jsx_primary_name_after
    | mdx_jsx_member_name_before
    | mdx_jsx_member_name
    | mdx_jsx_member_name_after
    | mdx_jsx_local_name_before
    | mdx_jsx_local_name
    | mdx_jsx_local_name_after
    | mdx_jsx_attribute_before
    | mdx_jsx_self_closing
    | mdx_jsx_attribute_expression_after
    | mdx_jsx_attribute_primary_name
    | mdx_jsx_attribute_primary_name_after
    | mdx_jsx_attribute_local_name_before
    | mdx_jsx_attribute_local_name
    | mdx_jsx_attribute_local_name_after
    | mdx_jsx_attribute_value_before
    | mdx_jsx_attribute_value_quoted_start
    | mdx_jsx_attribute_value_quoted
    | mdx_jsx_attribute_value_expression_after
    | mdx_jsx_es_whitespace_start
    | mdx_jsx_es_whitespace_inside
    | mdx_jsx_es_whitespace_eol_after
    | non_lazy_continuation_start
    | non_lazy_continuation_after
    | paragraph_start
    | paragraph_line_start
    | paragraph_inside
    | raw_flow_start
    | raw_flow_before_sequence_open
    | raw_flow_sequence_open
    | raw_flow_info_before
    | raw_flow_info
    | raw_flow_meta_before
    | raw_flow_meta
    | raw_flow_at_non_lazy_break
    | raw_flow_close_start
    | raw_flow_before_sequence_close
    | raw_flow_sequence_close
    | raw_flow_after_sequence_close
    | raw_flow_content_before
    | raw_flow_content_start
    | raw_flow_before_content_chunk
    | raw_flow_content_chunk
    | raw_flow_after
    | raw_text_start
    | raw_text_sequence_open
    | raw_text_between
    | raw_text_data
    | raw_text_sequence_close
    | space_or_tab_start
    | space_or_tab_inside
    | space_or_tab_after
    | space_or_tab_eol_start
    | space_or_tab_eol_after_first
    | space_or_tab_eol_after_eol
    | space_or_tab_eol_at_eol
    | space_or_tab_eol_after_more
    | string_start
    | string_before
    | string_before_data
    | text_start
    | text_before
    | text_before_html
    | text_before_mdx_jsx
    | text_before_hard_break_escape
    | text_before_label_start_link
    | text_before_data
    | thematic_break_start
    | thematic_break_before
    | thematic_break_sequence
    | thematic_break_at_break
    | title_start
    | title_begin
    | title_after_eol
    | title_at_break
    | title_escape
    | title_inside
    | title_nok.

-doc "Move to `name()` next.".
-type next() :: {next, name()}.

-doc "The state is not successful.".
-type nok() :: nok.

-doc "The state is successful.".
-type ok() :: ok.

-doc "Retry in `name()`.".
-type retry() :: {retry, name()}.

-doc "Result of a state.".
-type t() :: error() | next() | retry() | ok() | nok().

-export_type([
    error/0,
    name/0,
    next/0,
    nok/0,
    ok/0,
    retry/0,
    t/0
]).

%%%=============================================================================
%%% API functions
%%%=============================================================================

-doc """
Syntax error.

Only used by MDX.
""".
-spec error(Message) -> State when Message :: markdown_message:t(), State :: t().
-compile({inline, [error/1]}).
error(Message = #markdown_message{}) -> {error, Message}.

-doc "Move to `name()` next.".
-spec next(Name) -> State when Name :: name(), State :: t().
-compile({inline, [next/1]}).
next(Name) when ?is_markdown_state_name(Name) -> {next, Name}.

-doc "The state is not successful.".
-spec nok() -> State when State :: t().
-compile({inline, [nok/0]}).
nok() -> nok.

-doc "The state is successful.".
-spec ok() -> State when State :: t().
-compile({inline, [ok/0]}).
ok() -> ok.

-doc "Retry in `name()`.".
-spec retry(Name) -> State when Name :: name(), State :: t().
-compile({inline, [retry/1]}).
retry(Name) when ?is_markdown_state_name(Name) -> {retry, Name}.

-doc """
Turn a final state into a result.

This doesnâ€™t work on future states ([`State::Next`], [`State::Retry`]),
or on an attempt ([`State::Nok`]).

But it turns the final result into an error if crashed.
""".
-spec to_result(State) -> ok | {error, Message} when State :: t(), Message :: markdown_message:t().
-compile({inline, [to_result/1]}).
to_result(ok) -> ok;
to_result({error, Message = #markdown_message{}}) -> {error, Message}.

%%%=============================================================================
%%% Call API functions
%%%=============================================================================

-spec call(Tokenizer, Name) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), Name :: name(), State :: t().
call(Tokenizer1 = #markdown_tokenizer{}, Name) when ?is_markdown_state_name(Name) ->
    % TokenizerBeforeString = markdown_debug:rust_debug_string(Tokenizer1),
    % io:format("\n\n[~w:~w] BEFORE state:~ts\n\n", [markdown:counter_get(), markdown:stack_push(), markdown_debug:rust_debug_string(Name)]),
    {Tokenizer2, State} = ?MODULE:Name(Tokenizer1),
    % TokenizerAfterString = markdown_debug:rust_debug_string(Tokenizer2),
    % TokenizerString =
    %     case TokenizerBeforeString =:= TokenizerAfterString of
    %         true ->
    %             <<"NO CHANGE">>;
    %         false ->
    %             TokenizerAfterString
    %     end,
    % io:format("\n\n[~w:~w] AFTER state:~ts\n~ts\n~ts\n\n", [markdown:counter_get(), markdown:stack_pop(), markdown_debug:rust_debug_string(Name), markdown_debug:rust_debug_string(State), TokenizerString]),
    {Tokenizer2, State}.

-spec attention_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attention_start/1]}).
attention_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_attention:'start'(Tokenizer).

-spec attention_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attention_inside/1]}).
attention_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_attention:'inside'(Tokenizer).

-spec attribute_list_flow_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attribute_list_flow_start/1]}).
attribute_list_flow_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_attribute_list_flow:'start'(Tokenizer).

-spec attribute_list_flow_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attribute_list_flow_before/1]}).
attribute_list_flow_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_attribute_list_flow:'before'(Tokenizer).

-spec attribute_list_flow_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attribute_list_flow_after/1]}).
attribute_list_flow_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_attribute_list_flow:'after'(Tokenizer).

-spec attribute_list_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attribute_list_start/1]}).
attribute_list_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_attribute_list:'start'(Tokenizer).

-spec attribute_list_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attribute_list_before/1]}).
attribute_list_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_attribute_list:'before'(Tokenizer).

-spec attribute_list_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attribute_list_inside/1]}).
attribute_list_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_attribute_list:'inside'(Tokenizer).

-spec attribute_list_eol_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [attribute_list_eol_after/1]}).
attribute_list_eol_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_attribute_list:'eol_after'(Tokenizer).

-spec autolink_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_start/1]}).
autolink_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'start'(Tokenizer).

-spec autolink_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_open/1]}).
autolink_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'open'(Tokenizer).

-spec autolink_scheme_or_email_atext(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_scheme_or_email_atext/1]}).
autolink_scheme_or_email_atext(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'scheme_or_email_atext'(Tokenizer).

-spec autolink_scheme_inside_or_email_atext(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_scheme_inside_or_email_atext/1]}).
autolink_scheme_inside_or_email_atext(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'scheme_inside_or_email_atext'(Tokenizer).

-spec autolink_url_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_url_inside/1]}).
autolink_url_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'url_inside'(Tokenizer).

-spec autolink_email_at_sign_or_dot(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_email_at_sign_or_dot/1]}).
autolink_email_at_sign_or_dot(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'email_at_sign_or_dot'(Tokenizer).

-spec autolink_email_atext(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_email_atext/1]}).
autolink_email_atext(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'email_atext'(Tokenizer).

-spec autolink_email_value(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_email_value/1]}).
autolink_email_value(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'email_value'(Tokenizer).

-spec autolink_email_label(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [autolink_email_label/1]}).
autolink_email_label(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_autolink:'email_label'(Tokenizer).

-spec blank_line_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [blank_line_start/1]}).
blank_line_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_blank_line:'start'(Tokenizer).

-spec blank_line_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [blank_line_after/1]}).
blank_line_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_blank_line:'after'(Tokenizer).

-spec block_quote_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [block_quote_start/1]}).
block_quote_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_block_quote:'start'(Tokenizer).

-spec block_quote_cont_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [block_quote_cont_start/1]}).
block_quote_cont_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_block_quote:'cont_start'(Tokenizer).

-spec block_quote_cont_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [block_quote_cont_before/1]}).
block_quote_cont_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_block_quote:'cont_before'(Tokenizer).

-spec block_quote_cont_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [block_quote_cont_after/1]}).
block_quote_cont_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_block_quote:'cont_after'(Tokenizer).

-spec bom_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [bom_start/1]}).
bom_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_bom:'start'(Tokenizer).

-spec bom_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [bom_inside/1]}).
bom_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_bom:'inside'(Tokenizer).

-spec character_escape_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [character_escape_start/1]}).
character_escape_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_character_escape:'start'(Tokenizer).

-spec character_escape_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [character_escape_inside/1]}).
character_escape_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_character_escape:'inside'(Tokenizer).

-spec character_reference_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [character_reference_start/1]}).
character_reference_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_character_reference:'start'(Tokenizer).

-spec character_reference_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [character_reference_open/1]}).
character_reference_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_character_reference:'open'(Tokenizer).

-spec character_reference_numeric(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [character_reference_numeric/1]}).
character_reference_numeric(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_character_reference:'numeric'(Tokenizer).

-spec character_reference_value(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [character_reference_value/1]}).
character_reference_value(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_character_reference:'value'(Tokenizer).

-spec code_indented_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [code_indented_start/1]}).
code_indented_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_code_indented:'start'(Tokenizer).

-spec code_indented_at_break(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [code_indented_at_break/1]}).
code_indented_at_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_code_indented:'at_break'(Tokenizer).

-spec code_indented_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [code_indented_after/1]}).
code_indented_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_code_indented:'after'(Tokenizer).

-spec code_indented_further_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [code_indented_further_start/1]}).
code_indented_further_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_code_indented:'further_start'(Tokenizer).

-spec code_indented_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [code_indented_inside/1]}).
code_indented_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_code_indented:'inside'(Tokenizer).

-spec code_indented_further_begin(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [code_indented_further_begin/1]}).
code_indented_further_begin(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_code_indented:'further_begin'(Tokenizer).

-spec code_indented_further_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [code_indented_further_after/1]}).
code_indented_further_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_code_indented:'further_after'(Tokenizer).

-spec content_chunk_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [content_chunk_start/1]}).
content_chunk_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_content:'chunk_start'(Tokenizer).

-spec content_chunk_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [content_chunk_inside/1]}).
content_chunk_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_content:'chunk_inside'(Tokenizer).

-spec content_definition_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [content_definition_before/1]}).
content_definition_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_content:'definition_before'(Tokenizer).

-spec content_definition_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [content_definition_after/1]}).
content_definition_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_content:'definition_after'(Tokenizer).

-spec data_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [data_start/1]}).
data_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_data:'start'(Tokenizer).

-spec data_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [data_inside/1]}).
data_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_data:'inside'(Tokenizer).

-spec data_at_break(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [data_at_break/1]}).
data_at_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_data:'at_break'(Tokenizer).

-spec definition_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_start/1]}).
definition_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'start'(Tokenizer).

-spec definition_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_before/1]}).
definition_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'before'(Tokenizer).

-spec definition_label_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_label_after/1]}).
definition_label_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'label_after'(Tokenizer).

-spec definition_label_nok(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_label_nok/1]}).
definition_label_nok(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'label_nok'(Tokenizer).

-spec definition_marker_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_marker_after/1]}).
definition_marker_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'marker_after'(Tokenizer).

-spec definition_destination_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_destination_before/1]}).
definition_destination_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'destination_before'(Tokenizer).

-spec definition_destination_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_destination_after/1]}).
definition_destination_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'destination_after'(Tokenizer).

-spec definition_destination_missing(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_destination_missing/1]}).
definition_destination_missing(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'destination_missing'(Tokenizer).

-spec definition_title_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_title_before/1]}).
definition_title_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'title_before'(Tokenizer).

-spec definition_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_after/1]}).
definition_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'after'(Tokenizer).

-spec definition_after_whitespace(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_after_whitespace/1]}).
definition_after_whitespace(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'after_whitespace'(Tokenizer).

-spec definition_title_before_marker(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_title_before_marker/1]}).
definition_title_before_marker(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'title_before_marker'(Tokenizer).

-spec definition_title_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_title_after/1]}).
definition_title_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'title_after'(Tokenizer).

-spec definition_title_after_optional_whitespace(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [definition_title_after_optional_whitespace/1]}).
definition_title_after_optional_whitespace(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_definition:'title_after_optional_whitespace'(Tokenizer).

-spec destination_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [destination_start/1]}).
destination_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_destination:'start'(Tokenizer).

-spec destination_enclosed_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [destination_enclosed_before/1]}).
destination_enclosed_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_destination:'enclosed_before'(Tokenizer).

-spec destination_enclosed(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [destination_enclosed/1]}).
destination_enclosed(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_destination:'enclosed'(Tokenizer).

-spec destination_enclosed_escape(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [destination_enclosed_escape/1]}).
destination_enclosed_escape(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_destination:'enclosed_escape'(Tokenizer).

-spec destination_raw(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [destination_raw/1]}).
destination_raw(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_destination:'raw'(Tokenizer).

-spec destination_raw_escape(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [destination_raw_escape/1]}).
destination_raw_escape(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_destination:'raw_escape'(Tokenizer).

-spec document_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_start/1]}).
document_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'start'(Tokenizer).

-spec document_before_frontmatter(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_before_frontmatter/1]}).
document_before_frontmatter(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'before_frontmatter'(Tokenizer).

-spec document_container_existing_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_container_existing_before/1]}).
document_container_existing_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'container_existing_before'(Tokenizer).

-spec document_container_existing_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_container_existing_after/1]}).
document_container_existing_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'container_existing_after'(Tokenizer).

-spec document_container_new_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_container_new_before/1]}).
document_container_new_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'container_new_before'(Tokenizer).

-spec document_container_new_before_not_block_quote(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_container_new_before_not_block_quote/1]}).
document_container_new_before_not_block_quote(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'container_new_before_not_block_quote'(Tokenizer).

-spec document_container_new_before_not_list(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_container_new_before_not_list/1]}).
document_container_new_before_not_list(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'container_new_before_not_list'(Tokenizer).

-spec document_container_new_before_not_gfm_footnote_definition(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_container_new_before_not_gfm_footnote_definition/1]}).
document_container_new_before_not_gfm_footnote_definition(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'container_new_before_not_footnote_definition'(Tokenizer).

-spec document_container_new_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_container_new_after/1]}).
document_container_new_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'container_new_after'(Tokenizer).

-spec document_containers_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_containers_after/1]}).
document_containers_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'containers_after'(Tokenizer).

-spec document_flow_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_flow_end/1]}).
document_flow_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'flow_end'(Tokenizer).

-spec document_flow_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [document_flow_inside/1]}).
document_flow_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_document:'flow_inside'(Tokenizer).

-spec flow_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_start/1]}).
flow_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'start'(Tokenizer).

-spec flow_before_attribute_list(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_attribute_list/1]}).
flow_before_attribute_list(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_attribute_list'(Tokenizer).

-spec flow_before_gfm_table(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_gfm_table/1]}).
flow_before_gfm_table(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_gfm_table'(Tokenizer).

-spec flow_before_code_indented(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_code_indented/1]}).
flow_before_code_indented(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_code_indented'(Tokenizer).

-spec flow_before_raw(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_raw/1]}).
flow_before_raw(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_raw'(Tokenizer).

-spec flow_before_html(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_html/1]}).
flow_before_html(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_html'(Tokenizer).

-spec flow_before_mdx_expression(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_mdx_expression/1]}).
flow_before_mdx_expression(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_mdx_expression'(Tokenizer).

-spec flow_before_mdx_jsx(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_mdx_jsx/1]}).
flow_before_mdx_jsx(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_mdx_jsx'(Tokenizer).

-spec flow_before_heading_atx(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_heading_atx/1]}).
flow_before_heading_atx(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_heading_atx'(Tokenizer).

-spec flow_before_heading_setext(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_heading_setext/1]}).
flow_before_heading_setext(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_heading_setext'(Tokenizer).

-spec flow_before_thematic_break(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_thematic_break/1]}).
flow_before_thematic_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_thematic_break'(Tokenizer).

-spec flow_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_after/1]}).
flow_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'after'(Tokenizer).

-spec flow_blank_line_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_blank_line_before/1]}).
flow_blank_line_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'blank_line_before'(Tokenizer).

-spec flow_blank_line_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_blank_line_after/1]}).
flow_blank_line_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'blank_line_after'(Tokenizer).

-spec flow_before_content(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [flow_before_content/1]}).
flow_before_content(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_flow:'before_content'(Tokenizer).

-spec frontmatter_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_start/1]}).
frontmatter_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'start'(Tokenizer).

-spec frontmatter_open_sequence(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_open_sequence/1]}).
frontmatter_open_sequence(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'open_sequence'(Tokenizer).

-spec frontmatter_open_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_open_after/1]}).
frontmatter_open_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'open_after'(Tokenizer).

-spec frontmatter_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_after/1]}).
frontmatter_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'after'(Tokenizer).

-spec frontmatter_content_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_content_start/1]}).
frontmatter_content_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'content_start'(Tokenizer).

-spec frontmatter_content_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_content_inside/1]}).
frontmatter_content_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'content_inside'(Tokenizer).

-spec frontmatter_content_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_content_end/1]}).
frontmatter_content_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'content_end'(Tokenizer).

-spec frontmatter_close_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_close_start/1]}).
frontmatter_close_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'close_start'(Tokenizer).

-spec frontmatter_close_sequence(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_close_sequence/1]}).
frontmatter_close_sequence(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'close_sequence'(Tokenizer).

-spec frontmatter_close_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [frontmatter_close_after/1]}).
frontmatter_close_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_frontmatter:'close_after'(Tokenizer).

-spec gfm_autolink_literal_protocol_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_protocol_start/1]}).
gfm_autolink_literal_protocol_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'protocol_start'(Tokenizer).

-spec gfm_autolink_literal_protocol_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_protocol_after/1]}).
gfm_autolink_literal_protocol_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'protocol_after'(Tokenizer).

-spec gfm_autolink_literal_protocol_prefix_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_protocol_prefix_inside/1]}).
gfm_autolink_literal_protocol_prefix_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'protocol_prefix_inside'(Tokenizer).

-spec gfm_autolink_literal_protocol_slashes_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_protocol_slashes_inside/1]}).
gfm_autolink_literal_protocol_slashes_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'protocol_slashes_inside'(Tokenizer).

-spec gfm_autolink_literal_www_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_www_after/1]}).
gfm_autolink_literal_www_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'www_after'(Tokenizer).

-spec gfm_autolink_literal_www_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_www_start/1]}).
gfm_autolink_literal_www_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'www_start'(Tokenizer).

-spec gfm_autolink_literal_www_prefix_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_www_prefix_inside/1]}).
gfm_autolink_literal_www_prefix_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'www_prefix_inside'(Tokenizer).

-spec gfm_autolink_literal_www_prefix_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_www_prefix_after/1]}).
gfm_autolink_literal_www_prefix_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'www_prefix_after'(Tokenizer).

-spec gfm_autolink_literal_domain_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_domain_inside/1]}).
gfm_autolink_literal_domain_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'domain_inside'(Tokenizer).

-spec gfm_autolink_literal_domain_at_punctuation(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_domain_at_punctuation/1]}).
gfm_autolink_literal_domain_at_punctuation(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'domain_at_punctuation'(Tokenizer).

-spec gfm_autolink_literal_domain_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_domain_after/1]}).
gfm_autolink_literal_domain_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'domain_after'(Tokenizer).

-spec gfm_autolink_literal_path_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_path_inside/1]}).
gfm_autolink_literal_path_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'path_inside'(Tokenizer).

-spec gfm_autolink_literal_path_at_punctuation(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_path_at_punctuation/1]}).
gfm_autolink_literal_path_at_punctuation(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'path_at_punctuation'(Tokenizer).

-spec gfm_autolink_literal_path_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_path_after/1]}).
gfm_autolink_literal_path_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'path_after'(Tokenizer).

-spec gfm_autolink_literal_trail(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_trail/1]}).
gfm_autolink_literal_trail(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'trail'(Tokenizer).

-spec gfm_autolink_literal_trail_char_ref_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_trail_char_ref_start/1]}).
gfm_autolink_literal_trail_char_ref_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'trail_char_ref_start'(Tokenizer).

-spec gfm_autolink_literal_trail_char_ref_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_trail_char_ref_inside/1]}).
gfm_autolink_literal_trail_char_ref_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'trail_char_ref_inside'(Tokenizer).

-spec gfm_autolink_literal_trail_bracket_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_autolink_literal_trail_bracket_after/1]}).
gfm_autolink_literal_trail_bracket_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_autolink_literal:'trail_bracket_after'(Tokenizer).

-spec gfm_footnote_definition_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_start/1]}).
gfm_footnote_definition_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'start'(Tokenizer).

-spec gfm_footnote_definition_label_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_label_before/1]}).
gfm_footnote_definition_label_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'label_before'(Tokenizer).

-spec gfm_footnote_definition_label_at_marker(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_label_at_marker/1]}).
gfm_footnote_definition_label_at_marker(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'label_at_marker'(Tokenizer).

-spec gfm_footnote_definition_label_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_label_inside/1]}).
gfm_footnote_definition_label_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'label_inside'(Tokenizer).

-spec gfm_footnote_definition_label_escape(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_label_escape/1]}).
gfm_footnote_definition_label_escape(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'label_escape'(Tokenizer).

-spec gfm_footnote_definition_label_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_label_after/1]}).
gfm_footnote_definition_label_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'label_after'(Tokenizer).

-spec gfm_footnote_definition_whitespace_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_whitespace_after/1]}).
gfm_footnote_definition_whitespace_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'whitespace_after'(Tokenizer).

-spec gfm_footnote_definition_cont_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_cont_start/1]}).
gfm_footnote_definition_cont_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'cont_start'(Tokenizer).

-spec gfm_footnote_definition_cont_blank(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_cont_blank/1]}).
gfm_footnote_definition_cont_blank(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'cont_blank'(Tokenizer).

-spec gfm_footnote_definition_cont_filled(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_footnote_definition_cont_filled/1]}).
gfm_footnote_definition_cont_filled(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_footnote_definition:'cont_filled'(Tokenizer).

-spec gfm_label_start_footnote_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_label_start_footnote_start/1]}).
gfm_label_start_footnote_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_label_start_footnote:'start'(Tokenizer).

-spec gfm_label_start_footnote_open(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_label_start_footnote_open/1]}).
gfm_label_start_footnote_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_label_start_footnote:'open'(Tokenizer).

-spec gfm_table_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_start/1]}).
gfm_table_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'start'(Tokenizer).

-spec gfm_table_head_row_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_row_before/1]}).
gfm_table_head_row_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_row_before'(Tokenizer).

-spec gfm_table_head_row_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_row_start/1]}).
gfm_table_head_row_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_row_start'(Tokenizer).

-spec gfm_table_head_row_break(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_row_break/1]}).
gfm_table_head_row_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_row_break'(Tokenizer).

-spec gfm_table_head_row_data(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_row_data/1]}).
gfm_table_head_row_data(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_row_data'(Tokenizer).

-spec gfm_table_head_row_escape(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_row_escape/1]}).
gfm_table_head_row_escape(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_row_escape'(Tokenizer).

-spec gfm_table_head_delimiter_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_start/1]}).
gfm_table_head_delimiter_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_start'(Tokenizer).

-spec gfm_table_head_delimiter_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_before/1]}).
gfm_table_head_delimiter_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_before'(Tokenizer).

-spec gfm_table_head_delimiter_cell_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_cell_before/1]}).
gfm_table_head_delimiter_cell_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_cell_before'(Tokenizer).

-spec gfm_table_head_delimiter_value_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_value_before/1]}).
gfm_table_head_delimiter_value_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_value_before'(Tokenizer).

-spec gfm_table_head_delimiter_left_alignment_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_left_alignment_after/1]}).
gfm_table_head_delimiter_left_alignment_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_left_alignment_after'(Tokenizer).

-spec gfm_table_head_delimiter_filler(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_filler/1]}).
gfm_table_head_delimiter_filler(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_filler'(Tokenizer).

-spec gfm_table_head_delimiter_right_alignment_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_right_alignment_after/1]}).
gfm_table_head_delimiter_right_alignment_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_right_alignment_after'(Tokenizer).

-spec gfm_table_head_delimiter_cell_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_cell_after/1]}).
gfm_table_head_delimiter_cell_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_cell_after'(Tokenizer).

-spec gfm_table_head_delimiter_nok(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_head_delimiter_nok/1]}).
gfm_table_head_delimiter_nok(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'head_delimiter_nok'(Tokenizer).

-spec gfm_table_body_row_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_body_row_start/1]}).
gfm_table_body_row_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'body_row_start'(Tokenizer).

-spec gfm_table_body_row_break(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_body_row_break/1]}).
gfm_table_body_row_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'body_row_break'(Tokenizer).

-spec gfm_table_body_row_data(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_body_row_data/1]}).
gfm_table_body_row_data(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'body_row_data'(Tokenizer).

-spec gfm_table_body_row_escape(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_table_body_row_escape/1]}).
gfm_table_body_row_escape(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_table:'body_row_escape'(Tokenizer).

-spec gfm_task_list_item_check_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_task_list_item_check_start/1]}).
gfm_task_list_item_check_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_task_list_item_check:'start'(Tokenizer).

-spec gfm_task_list_item_check_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_task_list_item_check_inside/1]}).
gfm_task_list_item_check_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_task_list_item_check:'inside'(Tokenizer).

-spec gfm_task_list_item_check_close(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_task_list_item_check_close/1]}).
gfm_task_list_item_check_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_task_list_item_check:'close'(Tokenizer).

-spec gfm_task_list_item_check_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_task_list_item_check_after/1]}).
gfm_task_list_item_check_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_task_list_item_check:'after'(Tokenizer).

-spec gfm_task_list_item_check_after_space_or_tab(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [gfm_task_list_item_check_after_space_or_tab/1]}).
gfm_task_list_item_check_after_space_or_tab(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_gfm_task_list_item_check:'after_space_or_tab'(Tokenizer).

-spec hard_break_escape_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [hard_break_escape_start/1]}).
hard_break_escape_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_hard_break_escape:'start'(Tokenizer).

-spec hard_break_escape_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [hard_break_escape_after/1]}).
hard_break_escape_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_hard_break_escape:'after'(Tokenizer).

-spec heading_atx_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_atx_start/1]}).
heading_atx_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_atx:'start'(Tokenizer).

-spec heading_atx_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_atx_before/1]}).
heading_atx_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_atx:'before'(Tokenizer).

-spec heading_atx_sequence_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_atx_sequence_open/1]}).
heading_atx_sequence_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_atx:'sequence_open'(Tokenizer).

-spec heading_atx_at_break(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_atx_at_break/1]}).
heading_atx_at_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_atx:'at_break'(Tokenizer).

-spec heading_atx_sequence_further(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_atx_sequence_further/1]}).
heading_atx_sequence_further(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_atx:'sequence_further'(Tokenizer).

-spec heading_atx_data(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_atx_data/1]}).
heading_atx_data(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_atx:'data'(Tokenizer).

-spec heading_setext_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_setext_start/1]}).
heading_setext_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_setext:'start'(Tokenizer).

-spec heading_setext_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_setext_before/1]}).
heading_setext_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_setext:'before'(Tokenizer).

-spec heading_setext_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_setext_inside/1]}).
heading_setext_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_setext:'inside'(Tokenizer).

-spec heading_setext_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [heading_setext_after/1]}).
heading_setext_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_heading_setext:'after'(Tokenizer).

-spec html_flow_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_start/1]}).
html_flow_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'start'(Tokenizer).

-spec html_flow_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_before/1]}).
html_flow_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'before'(Tokenizer).

-spec html_flow_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_open/1]}).
html_flow_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'open'(Tokenizer).

-spec html_flow_declaration_open(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_declaration_open/1]}).
html_flow_declaration_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'declaration_open'(Tokenizer).

-spec html_flow_comment_open_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_comment_open_inside/1]}).
html_flow_comment_open_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'comment_open_inside'(Tokenizer).

-spec html_flow_cdata_open_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_cdata_open_inside/1]}).
html_flow_cdata_open_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'cdata_open_inside'(Tokenizer).

-spec html_flow_tag_close_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_tag_close_start/1]}).
html_flow_tag_close_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'tag_close_start'(Tokenizer).

-spec html_flow_tag_name(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_tag_name/1]}).
html_flow_tag_name(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'tag_name'(Tokenizer).

-spec html_flow_basic_self_closing(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_basic_self_closing/1]}).
html_flow_basic_self_closing(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'basic_self_closing'(Tokenizer).

-spec html_flow_complete_closing_tag_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_closing_tag_after/1]}).
html_flow_complete_closing_tag_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_closing_tag_after'(Tokenizer).

-spec html_flow_complete_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_end/1]}).
html_flow_complete_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_end'(Tokenizer).

-spec html_flow_complete_attribute_name_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_attribute_name_before/1]}).
html_flow_complete_attribute_name_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_attribute_name_before'(Tokenizer).

-spec html_flow_complete_attribute_name(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_attribute_name/1]}).
html_flow_complete_attribute_name(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_attribute_name'(Tokenizer).

-spec html_flow_complete_attribute_name_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_attribute_name_after/1]}).
html_flow_complete_attribute_name_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_attribute_name_after'(Tokenizer).

-spec html_flow_complete_attribute_value_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_attribute_value_before/1]}).
html_flow_complete_attribute_value_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_attribute_value_before'(Tokenizer).

-spec html_flow_complete_attribute_value_quoted(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_attribute_value_quoted/1]}).
html_flow_complete_attribute_value_quoted(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_attribute_value_quoted'(Tokenizer).

-spec html_flow_complete_attribute_value_quoted_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_attribute_value_quoted_after/1]}).
html_flow_complete_attribute_value_quoted_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_attribute_value_quoted_after'(Tokenizer).

-spec html_flow_complete_attribute_value_unquoted(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_attribute_value_unquoted/1]}).
html_flow_complete_attribute_value_unquoted(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_attribute_value_unquoted'(Tokenizer).

-spec html_flow_complete_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_complete_after/1]}).
html_flow_complete_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'complete_after'(Tokenizer).

-spec html_flow_blank_line_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_blank_line_before/1]}).
html_flow_blank_line_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'blank_line_before'(Tokenizer).

-spec html_flow_continuation(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation/1]}).
html_flow_continuation(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation'(Tokenizer).

-spec html_flow_continuation_declaration_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_declaration_inside/1]}).
html_flow_continuation_declaration_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_declaration_inside'(Tokenizer).

-spec html_flow_continuation_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_after/1]}).
html_flow_continuation_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_after'(Tokenizer).

-spec html_flow_continuation_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_start/1]}).
html_flow_continuation_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_start'(Tokenizer).

-spec html_flow_continuation_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_before/1]}).
html_flow_continuation_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_before'(Tokenizer).

-spec html_flow_continuation_comment_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_comment_inside/1]}).
html_flow_continuation_comment_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_comment_inside'(Tokenizer).

-spec html_flow_continuation_raw_tag_open(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_raw_tag_open/1]}).
html_flow_continuation_raw_tag_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_raw_tag_open'(Tokenizer).

-spec html_flow_continuation_raw_end_tag(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_raw_end_tag/1]}).
html_flow_continuation_raw_end_tag(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_raw_end_tag'(Tokenizer).

-spec html_flow_continuation_close(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_close/1]}).
html_flow_continuation_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_close'(Tokenizer).

-spec html_flow_continuation_cdata_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_cdata_inside/1]}).
html_flow_continuation_cdata_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_cdata_inside'(Tokenizer).

-spec html_flow_continuation_start_non_lazy(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_flow_continuation_start_non_lazy/1]}).
html_flow_continuation_start_non_lazy(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_flow:'continuation_start_non_lazy'(Tokenizer).

-spec html_text_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_start/1]}).
html_text_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'start'(Tokenizer).

-spec html_text_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_open/1]}).
html_text_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'open'(Tokenizer).

-spec html_text_declaration_open(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_declaration_open/1]}).
html_text_declaration_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'declaration_open'(Tokenizer).

-spec html_text_tag_close_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_close_start/1]}).
html_text_tag_close_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_close_start'(Tokenizer).

-spec html_text_tag_close(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_close/1]}).
html_text_tag_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_close'(Tokenizer).

-spec html_text_tag_close_between(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_close_between/1]}).
html_text_tag_close_between(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_close_between'(Tokenizer).

-spec html_text_tag_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_open/1]}).
html_text_tag_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_open'(Tokenizer).

-spec html_text_tag_open_between(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_open_between/1]}).
html_text_tag_open_between(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_open_between'(Tokenizer).

-spec html_text_tag_open_attribute_name(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_open_attribute_name/1]}).
html_text_tag_open_attribute_name(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_open_attribute_name'(Tokenizer).

-spec html_text_tag_open_attribute_name_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_open_attribute_name_after/1]}).
html_text_tag_open_attribute_name_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_open_attribute_name_after'(Tokenizer).

-spec html_text_tag_open_attribute_value_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_open_attribute_value_before/1]}).
html_text_tag_open_attribute_value_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_open_attribute_value_before'(Tokenizer).

-spec html_text_tag_open_attribute_value_quoted(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_open_attribute_value_quoted/1]}).
html_text_tag_open_attribute_value_quoted(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_open_attribute_value_quoted'(Tokenizer).

-spec html_text_tag_open_attribute_value_quoted_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_open_attribute_value_quoted_after/1]}).
html_text_tag_open_attribute_value_quoted_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_open_attribute_value_quoted_after'(Tokenizer).

-spec html_text_tag_open_attribute_value_unquoted(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_tag_open_attribute_value_unquoted/1]}).
html_text_tag_open_attribute_value_unquoted(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'tag_open_attribute_value_unquoted'(Tokenizer).

-spec html_text_cdata(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_cdata/1]}).
html_text_cdata(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'cdata'(Tokenizer).

-spec html_text_cdata_open_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_cdata_open_inside/1]}).
html_text_cdata_open_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'cdata_open_inside'(Tokenizer).

-spec html_text_cdata_close(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_cdata_close/1]}).
html_text_cdata_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'cdata_close'(Tokenizer).

-spec html_text_cdata_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_cdata_end/1]}).
html_text_cdata_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'cdata_end'(Tokenizer).

-spec html_text_comment_open_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_comment_open_inside/1]}).
html_text_comment_open_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'comment_open_inside'(Tokenizer).

-spec html_text_comment(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_comment/1]}).
html_text_comment(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'comment'(Tokenizer).

-spec html_text_comment_close(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_comment_close/1]}).
html_text_comment_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'comment_close'(Tokenizer).

-spec html_text_comment_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_comment_end/1]}).
html_text_comment_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'comment_end'(Tokenizer).

-spec html_text_declaration(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_declaration/1]}).
html_text_declaration(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'declaration'(Tokenizer).

-spec html_text_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_end/1]}).
html_text_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'end'(Tokenizer).

-spec html_text_instruction(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_instruction/1]}).
html_text_instruction(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'instruction'(Tokenizer).

-spec html_text_instruction_close(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_instruction_close/1]}).
html_text_instruction_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'instruction_close'(Tokenizer).

-spec html_text_line_ending_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_line_ending_before/1]}).
html_text_line_ending_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'line_ending_before'(Tokenizer).

-spec html_text_line_ending_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_line_ending_after/1]}).
html_text_line_ending_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'line_ending_after'(Tokenizer).

-spec html_text_line_ending_after_prefix(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [html_text_line_ending_after_prefix/1]}).
html_text_line_ending_after_prefix(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_html_text:'line_ending_after_prefix'(Tokenizer).

-spec label_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_start/1]}).
label_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_label:'start'(Tokenizer).

-spec label_at_break(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_at_break/1]}).
label_at_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_label:'at_break'(Tokenizer).

-spec label_eol_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_eol_after/1]}).
label_eol_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_label:'eol_after'(Tokenizer).

-spec label_escape(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_escape/1]}).
label_escape(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_label:'escape'(Tokenizer).

-spec label_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_inside/1]}).
label_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_label:'inside'(Tokenizer).

-spec label_nok(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_nok/1]}).
label_nok(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_label:'nok'(Tokenizer).

-spec label_end_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_start/1]}).
label_end_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'start'(Tokenizer).

-spec label_end_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_after/1]}).
label_end_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'after'(Tokenizer).

-spec label_end_resource_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_resource_start/1]}).
label_end_resource_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'resource_start'(Tokenizer).

-spec label_end_resource_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_resource_before/1]}).
label_end_resource_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'resource_before'(Tokenizer).

-spec label_end_resource_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_resource_open/1]}).
label_end_resource_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'resource_open'(Tokenizer).

-spec label_end_resource_destination_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_resource_destination_after/1]}).
label_end_resource_destination_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'resource_destination_after'(Tokenizer).

-spec label_end_resource_destination_missing(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_resource_destination_missing/1]}).
label_end_resource_destination_missing(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'resource_destination_missing'(Tokenizer).

-spec label_end_resource_between(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_resource_between/1]}).
label_end_resource_between(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'resource_between'(Tokenizer).

-spec label_end_resource_title_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_resource_title_after/1]}).
label_end_resource_title_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'resource_title_after'(Tokenizer).

-spec label_end_resource_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_resource_end/1]}).
label_end_resource_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'resource_end'(Tokenizer).

-spec label_end_ok(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_ok/1]}).
label_end_ok(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'ok'(Tokenizer).

-spec label_end_nok(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_nok/1]}).
label_end_nok(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'nok'(Tokenizer).

-spec label_end_reference_full(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_reference_full/1]}).
label_end_reference_full(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'reference_full'(Tokenizer).

-spec label_end_reference_full_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_reference_full_after/1]}).
label_end_reference_full_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'reference_full_after'(Tokenizer).

-spec label_end_reference_full_missing(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_reference_full_missing/1]}).
label_end_reference_full_missing(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'reference_full_missing'(Tokenizer).

-spec label_end_reference_not_full(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_reference_not_full/1]}).
label_end_reference_not_full(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'reference_not_full'(Tokenizer).

-spec label_end_reference_collapsed(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_reference_collapsed/1]}).
label_end_reference_collapsed(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'reference_collapsed'(Tokenizer).

-spec label_end_reference_collapsed_open(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_end_reference_collapsed_open/1]}).
label_end_reference_collapsed_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_end:'reference_collapsed_open'(Tokenizer).

-spec label_start_image_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_start_image_start/1]}).
label_start_image_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_start_image:'start'(Tokenizer).

-spec label_start_image_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_start_image_open/1]}).
label_start_image_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_start_image:'open'(Tokenizer).

-spec label_start_image_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_start_image_after/1]}).
label_start_image_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_start_image:'after'(Tokenizer).

-spec label_start_link_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [label_start_link_start/1]}).
label_start_link_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_label_start_link:'start'(Tokenizer).

-spec list_item_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_start/1]}).
list_item_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'start'(Tokenizer).

-spec list_item_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_before/1]}).
list_item_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'before'(Tokenizer).

-spec list_item_before_ordered(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_before_ordered/1]}).
list_item_before_ordered(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'before_ordered'(Tokenizer).

-spec list_item_before_unordered(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_before_unordered/1]}).
list_item_before_unordered(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'before_unordered'(Tokenizer).

-spec list_item_value(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_value/1]}).
list_item_value(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'value'(Tokenizer).

-spec list_item_marker(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_marker/1]}).
list_item_marker(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'marker'(Tokenizer).

-spec list_item_marker_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_marker_after/1]}).
list_item_marker_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'marker_after'(Tokenizer).

-spec list_item_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_after/1]}).
list_item_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'after'(Tokenizer).

-spec list_item_marker_after_filled(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_marker_after_filled/1]}).
list_item_marker_after_filled(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'marker_after_filled'(Tokenizer).

-spec list_item_whitespace(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_whitespace/1]}).
list_item_whitespace(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'whitespace'(Tokenizer).

-spec list_item_whitespace_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_whitespace_after/1]}).
list_item_whitespace_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'whitespace_after'(Tokenizer).

-spec list_item_prefix_other(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_prefix_other/1]}).
list_item_prefix_other(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'prefix_other'(Tokenizer).

-spec list_item_cont_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_cont_start/1]}).
list_item_cont_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'cont_start'(Tokenizer).

-spec list_item_cont_blank(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_cont_blank/1]}).
list_item_cont_blank(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'cont_blank'(Tokenizer).

-spec list_item_cont_filled(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [list_item_cont_filled/1]}).
list_item_cont_filled(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_list_item:'cont_filled'(Tokenizer).

-spec mdx_esm_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_esm_start/1]}).
mdx_esm_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_esm:'start'(Tokenizer).

-spec mdx_esm_word(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_esm_word/1]}).
mdx_esm_word(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_esm:'word'(Tokenizer).

-spec mdx_esm_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_esm_inside/1]}).
mdx_esm_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_esm:'inside'(Tokenizer).

-spec mdx_esm_line_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_esm_line_start/1]}).
mdx_esm_line_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_esm:'line_start'(Tokenizer).

-spec mdx_esm_blank_line_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_esm_blank_line_before/1]}).
mdx_esm_blank_line_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_esm:'blank_line_before'(Tokenizer).

-spec mdx_esm_continuation_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_esm_continuation_start/1]}).
mdx_esm_continuation_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_esm:'continuation_start'(Tokenizer).

-spec mdx_esm_at_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_esm_at_end/1]}).
mdx_esm_at_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_esm:'at_end'(Tokenizer).

-spec mdx_expression_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_start/1]}).
mdx_expression_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_expression:'start'(Tokenizer).

-spec mdx_expression_prefix(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_prefix/1]}).
mdx_expression_prefix(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_expression:'prefix'(Tokenizer).

-spec mdx_expression_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_before/1]}).
mdx_expression_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_expression:'before'(Tokenizer).

-spec mdx_expression_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_inside/1]}).
mdx_expression_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_expression:'inside'(Tokenizer).

-spec mdx_expression_eol_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_eol_after/1]}).
mdx_expression_eol_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_expression:'eol_after'(Tokenizer).

-spec mdx_expression_flow_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_flow_start/1]}).
mdx_expression_flow_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_expression_flow:'start'(Tokenizer).

-spec mdx_expression_flow_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_flow_before/1]}).
mdx_expression_flow_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_expression_flow:'before'(Tokenizer).

-spec mdx_expression_flow_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_flow_after/1]}).
mdx_expression_flow_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_expression_flow:'after'(Tokenizer).

-spec mdx_expression_flow_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_flow_end/1]}).
mdx_expression_flow_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_expression_flow:'end'(Tokenizer).

-spec mdx_expression_text_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_text_start/1]}).
mdx_expression_text_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_expression_text:'start'(Tokenizer).

-spec mdx_expression_text_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_expression_text_after/1]}).
mdx_expression_text_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_expression_text:'after'(Tokenizer).

-spec mdx_jsx_flow_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_flow_start/1]}).
mdx_jsx_flow_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_jsx_flow:'start'(Tokenizer).

-spec mdx_jsx_flow_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_flow_before/1]}).
mdx_jsx_flow_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_jsx_flow:'before'(Tokenizer).

-spec mdx_jsx_flow_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_flow_after/1]}).
mdx_jsx_flow_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_jsx_flow:'after'(Tokenizer).

-spec mdx_jsx_flow_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_flow_end/1]}).
mdx_jsx_flow_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_jsx_flow:'end'(Tokenizer).

-spec mdx_jsx_flow_nok(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_flow_nok/1]}).
mdx_jsx_flow_nok(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_jsx_flow:'nok'(Tokenizer).

-spec mdx_jsx_text_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_text_start/1]}).
mdx_jsx_text_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_jsx_text:'start'(Tokenizer).

-spec mdx_jsx_text_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_text_after/1]}).
mdx_jsx_text_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_jsx_text:'after'(Tokenizer).

-spec mdx_jsx_text_nok(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_text_nok/1]}).
mdx_jsx_text_nok(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_mdx_jsx_text:'nok'(Tokenizer).

-spec mdx_jsx_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_start/1]}).
mdx_jsx_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'start'(Tokenizer).

-spec mdx_jsx_start_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_start_after/1]}).
mdx_jsx_start_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'start_after'(Tokenizer).

-spec mdx_jsx_name_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_name_before/1]}).
mdx_jsx_name_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'name_before'(Tokenizer).

-spec mdx_jsx_closing_tag_name_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_closing_tag_name_before/1]}).
mdx_jsx_closing_tag_name_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'closing_tag_name_before'(Tokenizer).

-spec mdx_jsx_tag_end(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_tag_end/1]}).
mdx_jsx_tag_end(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'tag_end'(Tokenizer).

-spec mdx_jsx_primary_name(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_primary_name/1]}).
mdx_jsx_primary_name(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'primary_name'(Tokenizer).

-spec mdx_jsx_primary_name_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_primary_name_after/1]}).
mdx_jsx_primary_name_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'primary_name_after'(Tokenizer).

-spec mdx_jsx_member_name_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_member_name_before/1]}).
mdx_jsx_member_name_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'member_name_before'(Tokenizer).

-spec mdx_jsx_member_name(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_member_name/1]}).
mdx_jsx_member_name(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'member_name'(Tokenizer).

-spec mdx_jsx_member_name_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_member_name_after/1]}).
mdx_jsx_member_name_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'member_name_after'(Tokenizer).

-spec mdx_jsx_local_name_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_local_name_before/1]}).
mdx_jsx_local_name_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'local_name_before'(Tokenizer).

-spec mdx_jsx_local_name(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_local_name/1]}).
mdx_jsx_local_name(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'local_name'(Tokenizer).

-spec mdx_jsx_local_name_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_local_name_after/1]}).
mdx_jsx_local_name_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'local_name_after'(Tokenizer).

-spec mdx_jsx_attribute_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_before/1]}).
mdx_jsx_attribute_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_before'(Tokenizer).

-spec mdx_jsx_self_closing(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_self_closing/1]}).
mdx_jsx_self_closing(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'self_closing'(Tokenizer).

-spec mdx_jsx_attribute_expression_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_expression_after/1]}).
mdx_jsx_attribute_expression_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_expression_after'(Tokenizer).

-spec mdx_jsx_attribute_primary_name(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_primary_name/1]}).
mdx_jsx_attribute_primary_name(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_primary_name'(Tokenizer).

-spec mdx_jsx_attribute_primary_name_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_primary_name_after/1]}).
mdx_jsx_attribute_primary_name_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_primary_name_after'(Tokenizer).

-spec mdx_jsx_attribute_local_name_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_local_name_before/1]}).
mdx_jsx_attribute_local_name_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_local_name_before'(Tokenizer).

-spec mdx_jsx_attribute_local_name(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_local_name/1]}).
mdx_jsx_attribute_local_name(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_local_name'(Tokenizer).

-spec mdx_jsx_attribute_local_name_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_local_name_after/1]}).
mdx_jsx_attribute_local_name_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_local_name_after'(Tokenizer).

-spec mdx_jsx_attribute_value_before(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_value_before/1]}).
mdx_jsx_attribute_value_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_value_before'(Tokenizer).

-spec mdx_jsx_attribute_value_quoted_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_value_quoted_start/1]}).
mdx_jsx_attribute_value_quoted_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_value_quoted_start'(Tokenizer).

-spec mdx_jsx_attribute_value_quoted(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_value_quoted/1]}).
mdx_jsx_attribute_value_quoted(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_value_quoted'(Tokenizer).

-spec mdx_jsx_attribute_value_expression_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_attribute_value_expression_after/1]}).
mdx_jsx_attribute_value_expression_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'attribute_value_expression_after'(Tokenizer).

-spec mdx_jsx_es_whitespace_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_es_whitespace_start/1]}).
mdx_jsx_es_whitespace_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'es_whitespace_start'(Tokenizer).

-spec mdx_jsx_es_whitespace_inside(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_es_whitespace_inside/1]}).
mdx_jsx_es_whitespace_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'es_whitespace_inside'(Tokenizer).

-spec mdx_jsx_es_whitespace_eol_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [mdx_jsx_es_whitespace_eol_after/1]}).
mdx_jsx_es_whitespace_eol_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_mdx_jsx:'es_whitespace_eol_after'(Tokenizer).

-spec non_lazy_continuation_start(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [non_lazy_continuation_start/1]}).
non_lazy_continuation_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_non_lazy_continuation:'start'(Tokenizer).

-spec non_lazy_continuation_after(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [non_lazy_continuation_after/1]}).
non_lazy_continuation_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_non_lazy_continuation:'after'(Tokenizer).

-spec paragraph_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [paragraph_start/1]}).
paragraph_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_paragraph:'start'(Tokenizer).

-spec paragraph_line_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [paragraph_line_start/1]}).
paragraph_line_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_paragraph:'line_start'(Tokenizer).

-spec paragraph_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [paragraph_inside/1]}).
paragraph_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_paragraph:'inside'(Tokenizer).

-spec raw_flow_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_start/1]}).
raw_flow_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'start'(Tokenizer).

-spec raw_flow_before_sequence_open(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_before_sequence_open/1]}).
raw_flow_before_sequence_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'before_sequence_open'(Tokenizer).

-spec raw_flow_sequence_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_sequence_open/1]}).
raw_flow_sequence_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'sequence_open'(Tokenizer).

-spec raw_flow_info_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_info_before/1]}).
raw_flow_info_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'info_before'(Tokenizer).

-spec raw_flow_info(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_info/1]}).
raw_flow_info(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'info'(Tokenizer).

-spec raw_flow_meta_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_meta_before/1]}).
raw_flow_meta_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'meta_before'(Tokenizer).

-spec raw_flow_meta(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_meta/1]}).
raw_flow_meta(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'meta'(Tokenizer).

-spec raw_flow_at_non_lazy_break(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_at_non_lazy_break/1]}).
raw_flow_at_non_lazy_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'at_non_lazy_break'(Tokenizer).

-spec raw_flow_close_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_close_start/1]}).
raw_flow_close_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'close_start'(Tokenizer).

-spec raw_flow_before_sequence_close(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_before_sequence_close/1]}).
raw_flow_before_sequence_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'before_sequence_close'(Tokenizer).

-spec raw_flow_sequence_close(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_sequence_close/1]}).
raw_flow_sequence_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'sequence_close'(Tokenizer).

-spec raw_flow_after_sequence_close(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_after_sequence_close/1]}).
raw_flow_after_sequence_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'sequence_close_after'(Tokenizer).

-spec raw_flow_content_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_content_before/1]}).
raw_flow_content_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'content_before'(Tokenizer).

-spec raw_flow_content_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_content_start/1]}).
raw_flow_content_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'content_start'(Tokenizer).

-spec raw_flow_before_content_chunk(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_before_content_chunk/1]}).
raw_flow_before_content_chunk(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'before_content_chunk'(Tokenizer).

-spec raw_flow_content_chunk(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_content_chunk/1]}).
raw_flow_content_chunk(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'content_chunk'(Tokenizer).

-spec raw_flow_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_flow_after/1]}).
raw_flow_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_flow:'after'(Tokenizer).

-spec raw_text_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_text_start/1]}).
raw_text_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_text:'start'(Tokenizer).

-spec raw_text_sequence_open(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_text_sequence_open/1]}).
raw_text_sequence_open(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_text:'sequence_open'(Tokenizer).

-spec raw_text_between(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_text_between/1]}).
raw_text_between(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_text:'between'(Tokenizer).

-spec raw_text_data(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_text_data/1]}).
raw_text_data(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_text:'data'(Tokenizer).

-spec raw_text_sequence_close(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [raw_text_sequence_close/1]}).
raw_text_sequence_close(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_raw_text:'sequence_close'(Tokenizer).

-spec space_or_tab_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [space_or_tab_start/1]}).
space_or_tab_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_space_or_tab:'start'(Tokenizer).

-spec space_or_tab_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [space_or_tab_inside/1]}).
space_or_tab_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_space_or_tab:'inside'(Tokenizer).

-spec space_or_tab_after(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [space_or_tab_after/1]}).
space_or_tab_after(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_space_or_tab:'after'(Tokenizer).

-spec space_or_tab_eol_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [space_or_tab_eol_start/1]}).
space_or_tab_eol_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_space_or_tab_eol:'start'(Tokenizer).

-spec space_or_tab_eol_after_first(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [space_or_tab_eol_after_first/1]}).
space_or_tab_eol_after_first(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_space_or_tab_eol:'after_first'(Tokenizer).

-spec space_or_tab_eol_after_eol(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [space_or_tab_eol_after_eol/1]}).
space_or_tab_eol_after_eol(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_space_or_tab_eol:'after_eol'(Tokenizer).

-spec space_or_tab_eol_at_eol(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [space_or_tab_eol_at_eol/1]}).
space_or_tab_eol_at_eol(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_space_or_tab_eol:'at_eol'(Tokenizer).

-spec space_or_tab_eol_after_more(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [space_or_tab_eol_after_more/1]}).
space_or_tab_eol_after_more(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_space_or_tab_eol:'after_more'(Tokenizer).

-spec string_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [string_start/1]}).
string_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_string:'start'(Tokenizer).

-spec string_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [string_before/1]}).
string_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_string:'before'(Tokenizer).

-spec string_before_data(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [string_before_data/1]}).
string_before_data(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_string:'before_data'(Tokenizer).

-spec text_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [text_start/1]}).
text_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_text:'start'(Tokenizer).

-spec text_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [text_before/1]}).
text_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_text:'before'(Tokenizer).

-spec text_before_html(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [text_before_html/1]}).
text_before_html(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_text:'before_html'(Tokenizer).

-spec text_before_mdx_jsx(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [text_before_mdx_jsx/1]}).
text_before_mdx_jsx(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_text:'before_mdx_jsx'(Tokenizer).

-spec text_before_hard_break_escape(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [text_before_hard_break_escape/1]}).
text_before_hard_break_escape(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_text:'before_hard_break_escape'(Tokenizer).

-spec text_before_label_start_link(Tokenizer) -> {Tokenizer, State} when
    Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [text_before_label_start_link/1]}).
text_before_label_start_link(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_text:'before_label_start_link'(Tokenizer).

-spec text_before_data(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [text_before_data/1]}).
text_before_data(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_text:'before_data'(Tokenizer).

-spec thematic_break_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [thematic_break_start/1]}).
thematic_break_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_thematic_break:'start'(Tokenizer).

-spec thematic_break_before(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [thematic_break_before/1]}).
thematic_break_before(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_thematic_break:'before'(Tokenizer).

-spec thematic_break_sequence(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [thematic_break_sequence/1]}).
thematic_break_sequence(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_thematic_break:'sequence'(Tokenizer).

-spec thematic_break_at_break(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [thematic_break_at_break/1]}).
thematic_break_at_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_thematic_break:'at_break'(Tokenizer).

-spec title_start(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [title_start/1]}).
title_start(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_title:'start'(Tokenizer).

-spec title_begin(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [title_begin/1]}).
title_begin(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_title:'begin'(Tokenizer).

-spec title_after_eol(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [title_after_eol/1]}).
title_after_eol(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_title:'after_eol'(Tokenizer).

-spec title_at_break(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [title_at_break/1]}).
title_at_break(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_title:'at_break'(Tokenizer).

-spec title_escape(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [title_escape/1]}).
title_escape(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_title:'escape'(Tokenizer).

-spec title_inside(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [title_inside/1]}).
title_inside(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_title:'inside'(Tokenizer).

-spec title_nok(Tokenizer) -> {Tokenizer, State} when Tokenizer :: markdown_tokenizer:t(), State :: t().
-compile({inline, [title_nok/1]}).
title_nok(Tokenizer = #markdown_tokenizer{}) ->
    markdown_construct_partial_title:'nok'(Tokenizer).
